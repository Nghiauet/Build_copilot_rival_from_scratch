{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load GPT and GPT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed \n",
    "generation_gpt = pipeline(\"text-generation\", model=\"openai-gpt\")\n",
    "generation_gpt2 = pipeline(\"text-generation\", model=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT size: 116.5M parameters\n",
      "GPT2 size: 124.4M parameters\n"
     ]
    }
   ],
   "source": [
    "def model_size(model):\n",
    "    return sum(t.numel() for t in model.parameters())\n",
    "print(f\"GPT size: {model_size(generation_gpt.model)/1000**2:.1f}M parameters\")\n",
    "print(f\"GPT2 size: {model_size(generation_gpt2.model)/1000**2:.1f}M parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:\n",
      "1.\n",
      "when they came back out. i went back into the room. i called my uncle in a panic. \" \n",
      " i put a comforting hand on her arm. \" we're going to find our uncle, okay? \" \n",
      " \" and what if somebody\n",
      "2.\n",
      "when they came back downstairs i held a small box for him. he tore it open and revealed the ring. it was smaller than a ring finger, but it was perfectly sized. i don't know if he was just pleased by the size or if\n",
      "3.\n",
      "when they came back from a trip into the mines when their hands started growing too big for their bodies. and the woman who had to deal with him came from a clan that had been under the leadership of a small group from the south of the mountains\n",
      "\n",
      "GPT2:\n",
      "1.\n",
      "when they came back (e.g. you didn't do the right thing). They never really put much effort into learning, although sometimes they would use the knowledge to do things incorrectly. Some people will never have used one of their basic skills\n",
      "2.\n",
      "when they came back from work\n",
      "\n",
      "I've always loved it when they take things back and put them back together\n",
      "\n",
      "I know this David, this David, this David does this David, but when it comes to us, all of us\n",
      "3.\n",
      "when they came back. He went up to them for a kiss.\n",
      "\n",
      "\"I don't have any idea why, you're a good guy.\"\n",
      "\n",
      "One of the kids was already wearing two shirts that said \"JEANIE\n"
     ]
    }
   ],
   "source": [
    "def enum_pipeline_output(pipe, prompt, num_return_sequences): \n",
    "    out = pipe(prompt, num_return_sequences=num_return_sequences,\n",
    "               clean_up_tokenization_spaces=True)\n",
    "    return \"\\n\".join(f\"{i+1}.\" + x[\"generated_text\"] for i, x in enumerate(out))\n",
    "prompt = \"\\nwhen they came back\"\n",
    "print(\"GPT:\\n\" + enum_pipeline_output(generation_gpt, prompt, 3))\n",
    "print()\n",
    "print(\"GPT2:\\n\" + enum_pipeline_output(generation_gpt2, prompt, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add all file in /mnt/data3/nghiaph/pull-github/pull-github-bucket-2109-ver3 to .json file \n",
    "# folder_path = \"/mnt/data3/nghiaph/pull-github/pull-github-bucket-2109-ver3/\" \n",
    "# for file in os.listdir(folder_path):\n",
    "#     file_path = os.path.join(folder_path, file)\n",
    "#     new_file_path = os.path.join(folder_path, file + '.json')\n",
    "#     os.rename(file_path, new_file_path)\n",
    "\n",
    "# print(\"All files have been renamed with the .json extension.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data3/nghiaph/huggingface/transformers\n"
     ]
    }
   ],
   "source": [
    "os.environ['TRANSFORMERS_CACHE'] = '/mnt/data3/nghiaph/huggingface/transformers'\n",
    "print(os.getenv('TRANSFORMERS_CACHE'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DownloadConfig\n",
    "download_config = DownloadConfig(delete_extracted=True,\n",
    "                                 cache_dir='/mnt/data3/nghiaph/huggingface/transformers/datasets') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DownloadConfig(cache_dir='/mnt/data3/nghiaph/huggingface/transformers/datasets', force_download=False, resume_download=False, local_files_only=False, proxies=None, user_agent=None, extract_compressed_file=False, force_extract=False, delete_extracted=True, use_etag=True, num_proc=None, max_retries=1, token=None, ignore_url_params=False, storage_options={'hf': {'token': None, 'endpoint': 'https://huggingface.co'}}, download_desc=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_dataset(path = \"/mnt/data3/nghiaph/pull-github/pull-github-bucket-2109-ver3/\", \n",
    "#                        split=\"train\",\n",
    "#                        download_config=download_config,\n",
    "#                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import psutil\n",
    "# import os\n",
    "# print(f\"Number of python files code in dataset : {len(dataset)}\")\n",
    "# ds_size = sum(os.stat(f[\"filename\"]).st_size for f in dataset.cache_files)\n",
    "# # os.stat.st_size is expressed in bytes, so we convert to GB\n",
    "# print(f\"Dataset size (cache file) : {ds_size / 2**30:.2f} GB\")\n",
    "# # Process.memory_info is expressed in bytes, so we convert to MB\n",
    "# print(f\"RAM used: {psutil.Process(os.getpid()).memory_info().rss >> 20} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd2c60d44084b18b66ef87dfbf46ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/583 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32396534c294a27ba0c9a413b41a7fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be117071614f42dda2f4d5a4e4aed641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093deed92c7a432bb625eb3fb559be68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4f59cfe3694fc1b7290c330269c77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/253M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35de21481c12453ab34887252577b632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/254M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a8f598b2074c7e891a27947bcb4a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/246M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6359ab1d0dae4f4a8b3c10dfc2e9ac36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/252M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5076dbcad0f4428ba61b4d7c37c18003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040924fd5a1c4059aa7e938660491492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/253M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10fc770aa79a452a9a377ca2eec793b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/252M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f604094fbbad4e69a26ced97eb585bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/253M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83e049c0c2c48c1be460da898442748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/252M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d42f55b8ea84764be5401e7f62bbe32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/250M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83025a74478e4c099d4559ab16251e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/253M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a566dcdf525c4708acc3c94ee222f492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/254M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2327fcc30df547f0b82ac336f971aadd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/253M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ec86c1eae6494daae04dbf0bd522c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/254M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9139fd2c53f249438e309427abdbb43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ff33ff793e4ac686706fdd31fad460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/250M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19c5870f84449f3b9e15736b0220dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/254M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962d4714dab04d2a9c89e414d42a76c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/251M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25aac49fa8f04a99bc62763996933367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/250M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b7255780104bfd9f29befb87db97c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/250M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4648b38ef2431a80e59b8d0309e0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/252M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "860f2b32ab3a4d67af0cbff7a4d2c709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/254M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7157a5cd45477e8fa25a20a7b127a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/250M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf42b1e271347e0944ed6fdae2d7b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/253M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04827bdefc8e4fb2beb70b75175426e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/251M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "streamed_dataset = load_dataset(\"transformersbook/codeparrot-train\",\n",
    "                                split=\"train\", \n",
    "                                # streaming=True,\n",
    "                                # download_config = download_config,\n",
    "                                \n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/GEC/GEC_env/lib/python3.8/site-packages/datasets/packaged_modules/json/json.py:121\u001b[0m, in \u001b[0;36mJson._generate_tables\u001b[0;34m(self, files)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     pa_table \u001b[39m=\u001b[39m paj\u001b[39m.\u001b[39;49mread_json(\n\u001b[1;32m    122\u001b[0m         io\u001b[39m.\u001b[39;49mBytesIO(batch), read_options\u001b[39m=\u001b[39;49mpaj\u001b[39m.\u001b[39;49mReadOptions(block_size\u001b[39m=\u001b[39;49mblock_size)\n\u001b[1;32m    123\u001b[0m     )\n\u001b[1;32m    124\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/GEC/GEC_env/lib/python3.8/site-packages/pyarrow/_json.pyx:258\u001b[0m, in \u001b[0;36mpyarrow._json.read_json\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/GEC/GEC_env/lib/python3.8/site-packages/pyarrow/error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/GEC/GEC_env/lib/python3.8/site-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: JSON parse error: Invalid value. in row 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/home/nghiaph/workspace_nghia/Build_copilot_rival_from_scratch/Load_data.ipynb Cell 14\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.166.128.149/home/nghiaph/workspace_nghia/Build_copilot_rival_from_scratch/Load_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m iterator \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(streamed_dataset)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.166.128.149/home/nghiaph/workspace_nghia/Build_copilot_rival_from_scratch/Load_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m next_item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(iterator)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.166.128.149/home/nghiaph/workspace_nghia/Build_copilot_rival_from_scratch/Load_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# extract json gzip file next_item \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.166.128.149/home/nghiaph/workspace_nghia/Build_copilot_rival_from_scratch/Load_data.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgzip\u001b[39;00m\n",
      "File \u001b[0;32m~/GEC/GEC_env/lib/python3.8/site-packages/datasets/iterable_dataset.py:1353\u001b[0m, in \u001b[0;36mIterableDataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1350\u001b[0m         \u001b[39myield\u001b[39;00m formatter\u001b[39m.\u001b[39mformat_row(pa_table)\n\u001b[1;32m   1351\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m-> 1353\u001b[0m \u001b[39mfor\u001b[39;00m key, example \u001b[39min\u001b[39;00m ex_iterable:\n\u001b[1;32m   1354\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures:\n\u001b[1;32m   1355\u001b[0m         \u001b[39m# `IterableDataset` automatically fills missing columns with None.\u001b[39;00m\n\u001b[1;32m   1356\u001b[0m         \u001b[39m# This is done with `_apply_feature_types_on_example`.\u001b[39;00m\n\u001b[1;32m   1357\u001b[0m         example \u001b[39m=\u001b[39m _apply_feature_types_on_example(\n\u001b[1;32m   1358\u001b[0m             example, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures, token_per_repo_id\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_token_per_repo_id\n\u001b[1;32m   1359\u001b[0m         )\n",
      "File \u001b[0;32m~/GEC/GEC_env/lib/python3.8/site-packages/datasets/iterable_dataset.py:255\u001b[0m, in \u001b[0;36mArrowExamplesIterable.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    254\u001b[0m     formatter \u001b[39m=\u001b[39m PythonFormatter()\n\u001b[0;32m--> 255\u001b[0m     \u001b[39mfor\u001b[39;00m key, pa_table \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_tables_fn(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs):\n\u001b[1;32m    256\u001b[0m         \u001b[39mfor\u001b[39;00m pa_subtable \u001b[39min\u001b[39;00m pa_table\u001b[39m.\u001b[39mto_reader(max_chunksize\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mARROW_READER_BATCH_SIZE_IN_DATASET_ITER):\n\u001b[1;32m    257\u001b[0m             formatted_batch \u001b[39m=\u001b[39m formatter\u001b[39m.\u001b[39mformat_batch(pa_subtable)\n",
      "File \u001b[0;32m~/GEC/GEC_env/lib/python3.8/site-packages/datasets/packaged_modules/json/json.py:144\u001b[0m, in \u001b[0;36mJson._generate_tables\u001b[0;34m(self, files)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    142\u001b[0m         file, encoding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mencoding, errors\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mencoding_errors\n\u001b[1;32m    143\u001b[0m     ) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m--> 144\u001b[0m         dataset \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mload(f)\n\u001b[1;32m    145\u001b[0m \u001b[39mexcept\u001b[39;00m json\u001b[39m.\u001b[39mJSONDecodeError:\n\u001b[1;32m    146\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to read file \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m with error \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(e)\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.8/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(fp, \u001b[39m*\u001b[39m, \u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, object_hook\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, parse_float\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, parse_constant\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, object_pairs_hook\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[39m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[39m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[39mreturn\u001b[39;00m loads(fp\u001b[39m.\u001b[39;49mread(),\n\u001b[1;32m    294\u001b[0m         \u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m, object_hook\u001b[39m=\u001b[39mobject_hook,\n\u001b[1;32m    295\u001b[0m         parse_float\u001b[39m=\u001b[39mparse_float, parse_int\u001b[39m=\u001b[39mparse_int,\n\u001b[1;32m    296\u001b[0m         parse_constant\u001b[39m=\u001b[39mparse_constant, object_pairs_hook\u001b[39m=\u001b[39mobject_pairs_hook, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[0;32m/usr/lib/python3.8/codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[39m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m+\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m--> 322\u001b[0m     (result, consumed) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer_decode(data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors, final)\n\u001b[1;32m    323\u001b[0m     \u001b[39m# keep undecoded input until the next call\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m=\u001b[39m data[consumed:]\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GEC_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
